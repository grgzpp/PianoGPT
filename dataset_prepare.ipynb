{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import miditok\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PARAMS = {\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_tempos\": True,\n",
    "    \"use_programs\": True,\n",
    "    \"one_token_stream_for_programs\": True,\n",
    "    \"use_time_signatures\": True\n",
    "}\n",
    "tokenizer = miditok.REMI(miditok.TokenizerConfig(**TOKENIZER_PARAMS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_paths = [os.path.join(\"giant_midi_piano\", midi_file) for midi_file in os.listdir(\"giant_midi_piano\")]\n",
    "# midi_paths = [os.path.join(\"giant_midi_piano\", midi_file.replace('.mid', '').replace('.', '').replace(',', '').replace(\"'\", '').replace(' ', '_') + \".mid\") for midi_file in os.listdir(\"giant_midi_piano\")]\n",
    "files_len = len(midi_paths)\n",
    "print(f\"Midi dataset len: {files_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: rename midi files, as the tokenizer sometimes is not working with strange filenames. This will rename all the midi files, so better save a copy before executing\n",
    "for i, midi_path in enumerate(midi_paths):\n",
    "    os.rename(midi_path, os.path.join(\"giant_midi_piano\", f\"track_{i}.mid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split midi tracks into chunks of the same length, optionally with overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tokens(input_list, n, overlap=0):\n",
    "    if len(input_list) < n:\n",
    "        return [input_list]\n",
    "    return [input_list[i:i + n] for i in range(0, len(input_list), n - overlap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_tokens_dataset_list = []\n",
    "df_chunks_list = []\n",
    "chunk_idx = 0\n",
    "for midi_path in tqdm(midi_paths):\n",
    "    filename = os.path.basename(midi_path).replace(\".mid\", '')\n",
    "    try:\n",
    "        token_ids = tokenizer.encode(midi_path).ids\n",
    "    except:\n",
    "        print(\"Error tokenizing file\", filename)\n",
    "        continue\n",
    "    token_ids.insert(0, 1)\n",
    "    token_ids.append(2)\n",
    "    chunks = split_tokens(token_ids, CHUNK_MAX_LEN + 1, overlap=32)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        tokens_len = len(chunk)\n",
    "        if tokens_len < (CHUNK_MAX_LEN + 1): # for now, no padding is applied, so non-complete chunks at the end will be discarded\n",
    "            continue\n",
    "\n",
    "        chunk_dict = {\n",
    "            \"filename\": filename,\n",
    "            \"chunk_idx\": chunk_idx,\n",
    "            \"chunk_sentence_idx\": i\n",
    "        }\n",
    "        chunk_idx += 1\n",
    "        midi_tokens_dataset_list.append(np.array(chunk))\n",
    "        df_chunks_list.append(chunk_dict)\n",
    "\n",
    "midi_tokens_dataset = np.array(midi_tokens_dataset_list)\n",
    "print(\"midi_tokens_dataset shape:\", midi_tokens_dataset.shape)\n",
    "midi_df = pd.DataFrame(df_chunks_list, columns=[\"filename\", \"chunk_idx\", \"chunk_sentence_idx\"])\n",
    "print(f\"Total chunks: {len(midi_df)}\")\n",
    "midi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset numpy array and descriptive csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"midi_tokens_dataset_512.npy\", midi_tokens_dataset)\n",
    "midi_df.to_csv(\"midi_dataset_512.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_tokens_dataset = torch.tensor(midi_tokens_dataset, dtype=torch.int64)\n",
    "unique_tokens = torch.unique(midi_tokens_dataset)\n",
    "np.save(\"unique_tokens.npy\", unique_tokens.numpy())\n",
    "vocab_size = len(unique_tokens)\n",
    "print(\"vocab_size\", vocab_size)\n",
    "unique_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
