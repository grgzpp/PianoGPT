{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import miditok\n",
    "import torch\n",
    "\n",
    "from nanogpt_model import GPTConfig, GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"out\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Resuming model from {out_dir}\")\n",
    "ckpt_path = os.path.join(out_dir, \"ckpt_beethoven.pt\") # ckpt_pre_trained.pt\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "checkpoint_model_args = checkpoint[\"model_args\"]\n",
    "\n",
    "gptconf = GPTConfig(**checkpoint_model_args)\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint[\"model\"]\n",
    "\n",
    "unwanted_prefix = \"_orig_mod.\"\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "iter_num = checkpoint[\"iter_num\"]\n",
    "best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load unique tokens used (this reduces the vocab size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = torch.from_numpy(np.load(\"unique_tokens.npy\"))\n",
    "vocab_size = len(unique_tokens)\n",
    "print(\"vocab_size\", vocab_size)\n",
    "unique_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define map functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_mapping = {unique_tokens[i].item(): i for i in range(len(unique_tokens))}\n",
    "tokens_unmapping = {i: unique_tokens[i].item() for i in range(len(unique_tokens))}\n",
    "print(tokens_mapping)\n",
    "print(tokens_unmapping)\n",
    "\n",
    "def map_tokens(tokens, tokens_mapping):\n",
    "    mapped_tokens = torch.zeros_like(tokens)\n",
    "    for i in range(len(tokens)):\n",
    "        mapped_tokens[i] = tokens_mapping[tokens[i].item()]\n",
    "    return mapped_tokens\n",
    "\n",
    "def unmap_tokens(mapped_tokens, tokens_unmapping):\n",
    "    unmapped_tokens = torch.zeros_like(mapped_tokens)\n",
    "    for i in range(len(mapped_tokens)):\n",
    "        unmapped_tokens[i] = tokens_unmapping[mapped_tokens[i].item()]\n",
    "    return unmapped_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PARAMS = {\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\", \"MASK\"],\n",
    "    \"use_tempos\": True,\n",
    "    \"use_programs\": True,\n",
    "    \"one_token_stream_for_programs\": True,\n",
    "    \"use_time_signatures\": True\n",
    "}\n",
    "tokenizer = miditok.REMI(miditok.TokenizerConfig(**TOKENIZER_PARAMS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 5 tracks from scratch, just providing the BOS (begin of sentence) token (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[1] for _ in range(5)], dtype=torch.int64).to(device)\n",
    "for i in range(len(inputs)):\n",
    "    inputs[i] = map_tokens(inputs[i], tokens_mapping)\n",
    "print(inputs.shape)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a midi file to generate a variation of it, truncating in the desired point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_midi_path = os.path.join(\"path\", \"to\", \"midi_file.mid\")\n",
    "input_token_ids = tokenizer.encode(input_midi_path).ids[:200] # use list slicing here to truncate the tokenized ids\n",
    "\n",
    "# Optionally save the truncated input midi to listen to it\n",
    "# input_midi = tokenizer.decode(input_token_ids)\n",
    "# input_midi.dump_midi(\"input.mid\")\n",
    "\n",
    "inputs = map_tokens(torch.tensor(input_token_ids, dtype=torch.int64), tokens_mapping).unsqueeze(0).to(device)\n",
    "print(inputs.shape)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs, max_new_tokens=(1024 - inputs.shape[1]), temperature=1.0) # generate a total of 1024 tokens, otherwise specify directly the new tokens to be generated\n",
    "print(outputs.shape)\n",
    "for i in range(len(outputs)):\n",
    "    outputs[i] = unmap_tokens(outputs[i], tokens_unmapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save outputs as midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(outputs.shape[0]):\n",
    "    output_midi = tokenizer.decode(outputs[i].tolist())\n",
    "    output_midi.dump_midi(f\"output_{i}.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
